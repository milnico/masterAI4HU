{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeESSQii1Yzu92aUGmZL8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milnico/masterAI4HU/blob/main/KERAS_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd\n",
        "\n",
        "# Load the iris dataset from sklearn\n",
        "wine = load_wine()\n",
        "\n",
        "# Convert the iris dataset to a pandas dataframe\n",
        "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAFNLFXTaZZv",
        "outputId": "4af0f621-a882-4351-c3b3-b19e47431a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
            "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
            "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
            "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
            "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
            "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
            "..       ...         ...   ...                ...        ...            ...   \n",
            "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
            "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
            "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
            "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
            "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
            "\n",
            "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
            "0          3.06                  0.28             2.29             5.64  1.04   \n",
            "1          2.76                  0.26             1.28             4.38  1.05   \n",
            "2          3.24                  0.30             2.81             5.68  1.03   \n",
            "3          3.49                  0.24             2.18             7.80  0.86   \n",
            "4          2.69                  0.39             1.82             4.32  1.04   \n",
            "..          ...                   ...              ...              ...   ...   \n",
            "173        0.61                  0.52             1.06             7.70  0.64   \n",
            "174        0.75                  0.43             1.41             7.30  0.70   \n",
            "175        0.69                  0.43             1.35            10.20  0.59   \n",
            "176        0.68                  0.53             1.46             9.30  0.60   \n",
            "177        0.76                  0.56             1.35             9.20  0.61   \n",
            "\n",
            "     od280/od315_of_diluted_wines  proline  \n",
            "0                            3.92   1065.0  \n",
            "1                            3.40   1050.0  \n",
            "2                            3.17   1185.0  \n",
            "3                            3.45   1480.0  \n",
            "4                            2.93    735.0  \n",
            "..                            ...      ...  \n",
            "173                          1.74    740.0  \n",
            "174                          1.56    750.0  \n",
            "175                          1.56    835.0  \n",
            "176                          1.62    840.0  \n",
            "177                          1.60    560.0  \n",
            "\n",
            "[178 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UZE_Y7m4M2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34a23dd2-29c3-40e8-eb6e-66f4fa373190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 8)                 112       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139 (556.00 Byte)\n",
            "Trainable params: 139 (556.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 76ms/step - loss: 0.9970 - accuracy: 0.4789 - val_loss: 1.0060 - val_accuracy: 0.3611\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9626 - accuracy: 0.5000 - val_loss: 0.9718 - val_accuracy: 0.4722\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9295 - accuracy: 0.5352 - val_loss: 0.9388 - val_accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8979 - accuracy: 0.5634 - val_loss: 0.9065 - val_accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8670 - accuracy: 0.6268 - val_loss: 0.8762 - val_accuracy: 0.5833\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8381 - accuracy: 0.6549 - val_loss: 0.8469 - val_accuracy: 0.6667\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8090 - accuracy: 0.6690 - val_loss: 0.8191 - val_accuracy: 0.6667\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7822 - accuracy: 0.6831 - val_loss: 0.7925 - val_accuracy: 0.6944\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7561 - accuracy: 0.7113 - val_loss: 0.7673 - val_accuracy: 0.7222\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7310 - accuracy: 0.7465 - val_loss: 0.7432 - val_accuracy: 0.7222\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7068 - accuracy: 0.7746 - val_loss: 0.7203 - val_accuracy: 0.7778\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6839 - accuracy: 0.7887 - val_loss: 0.6981 - val_accuracy: 0.8056\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6611 - accuracy: 0.8028 - val_loss: 0.6763 - val_accuracy: 0.8056\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6399 - accuracy: 0.8099 - val_loss: 0.6555 - val_accuracy: 0.8056\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6192 - accuracy: 0.8380 - val_loss: 0.6359 - val_accuracy: 0.8889\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5992 - accuracy: 0.8592 - val_loss: 0.6173 - val_accuracy: 0.8889\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5802 - accuracy: 0.8592 - val_loss: 0.5995 - val_accuracy: 0.8889\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5622 - accuracy: 0.8803 - val_loss: 0.5822 - val_accuracy: 0.9167\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5443 - accuracy: 0.8944 - val_loss: 0.5656 - val_accuracy: 0.9167\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5275 - accuracy: 0.9085 - val_loss: 0.5495 - val_accuracy: 0.9167\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5115 - accuracy: 0.9155 - val_loss: 0.5341 - val_accuracy: 0.9167\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4959 - accuracy: 0.9155 - val_loss: 0.5194 - val_accuracy: 0.9167\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4807 - accuracy: 0.9155 - val_loss: 0.5054 - val_accuracy: 0.9167\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4664 - accuracy: 0.9155 - val_loss: 0.4917 - val_accuracy: 0.9167\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4528 - accuracy: 0.9155 - val_loss: 0.4788 - val_accuracy: 0.9444\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4393 - accuracy: 0.9225 - val_loss: 0.4664 - val_accuracy: 0.9444\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4270 - accuracy: 0.9296 - val_loss: 0.4544 - val_accuracy: 0.9444\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4150 - accuracy: 0.9296 - val_loss: 0.4431 - val_accuracy: 0.9444\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4027 - accuracy: 0.9296 - val_loss: 0.4320 - val_accuracy: 0.9444\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.9366 - val_loss: 0.4213 - val_accuracy: 0.9444\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3807 - accuracy: 0.9296 - val_loss: 0.4114 - val_accuracy: 0.9444\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.9296 - val_loss: 0.4018 - val_accuracy: 0.9444\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3601 - accuracy: 0.9366 - val_loss: 0.3926 - val_accuracy: 0.9444\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3509 - accuracy: 0.9366 - val_loss: 0.3836 - val_accuracy: 0.9444\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3416 - accuracy: 0.9366 - val_loss: 0.3752 - val_accuracy: 0.9444\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3327 - accuracy: 0.9366 - val_loss: 0.3673 - val_accuracy: 0.9444\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3244 - accuracy: 0.9366 - val_loss: 0.3593 - val_accuracy: 0.9444\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3164 - accuracy: 0.9366 - val_loss: 0.3514 - val_accuracy: 0.9444\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3087 - accuracy: 0.9437 - val_loss: 0.3439 - val_accuracy: 0.9444\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3012 - accuracy: 0.9437 - val_loss: 0.3366 - val_accuracy: 0.9444\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2940 - accuracy: 0.9437 - val_loss: 0.3296 - val_accuracy: 0.9444\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2873 - accuracy: 0.9507 - val_loss: 0.3230 - val_accuracy: 0.9722\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2805 - accuracy: 0.9507 - val_loss: 0.3167 - val_accuracy: 0.9722\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2740 - accuracy: 0.9437 - val_loss: 0.3104 - val_accuracy: 0.9722\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2680 - accuracy: 0.9437 - val_loss: 0.3044 - val_accuracy: 0.9722\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2620 - accuracy: 0.9437 - val_loss: 0.2986 - val_accuracy: 0.9722\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2562 - accuracy: 0.9437 - val_loss: 0.2931 - val_accuracy: 0.9722\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2509 - accuracy: 0.9437 - val_loss: 0.2876 - val_accuracy: 0.9722\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9437 - val_loss: 0.2826 - val_accuracy: 0.9722\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2404 - accuracy: 0.9437 - val_loss: 0.2775 - val_accuracy: 0.9722\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2354 - accuracy: 0.9437 - val_loss: 0.2726 - val_accuracy: 0.9722\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2306 - accuracy: 0.9437 - val_loss: 0.2679 - val_accuracy: 0.9722\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2260 - accuracy: 0.9437 - val_loss: 0.2633 - val_accuracy: 0.9722\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2216 - accuracy: 0.9437 - val_loss: 0.2588 - val_accuracy: 0.9722\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2173 - accuracy: 0.9437 - val_loss: 0.2545 - val_accuracy: 0.9722\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2132 - accuracy: 0.9437 - val_loss: 0.2503 - val_accuracy: 0.9722\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2090 - accuracy: 0.9437 - val_loss: 0.2463 - val_accuracy: 0.9722\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2051 - accuracy: 0.9437 - val_loss: 0.2424 - val_accuracy: 0.9722\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2013 - accuracy: 0.9437 - val_loss: 0.2385 - val_accuracy: 0.9722\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1975 - accuracy: 0.9437 - val_loss: 0.2348 - val_accuracy: 0.9722\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1940 - accuracy: 0.9437 - val_loss: 0.2311 - val_accuracy: 0.9722\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9437 - val_loss: 0.2276 - val_accuracy: 0.9722\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1872 - accuracy: 0.9507 - val_loss: 0.2242 - val_accuracy: 0.9722\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1840 - accuracy: 0.9507 - val_loss: 0.2209 - val_accuracy: 0.9722\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1806 - accuracy: 0.9577 - val_loss: 0.2176 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1774 - accuracy: 0.9577 - val_loss: 0.2143 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1743 - accuracy: 0.9648 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1714 - accuracy: 0.9648 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1685 - accuracy: 0.9648 - val_loss: 0.2049 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1656 - accuracy: 0.9648 - val_loss: 0.2019 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1630 - accuracy: 0.9718 - val_loss: 0.1991 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1601 - accuracy: 0.9718 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1576 - accuracy: 0.9718 - val_loss: 0.1933 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1551 - accuracy: 0.9718 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1526 - accuracy: 0.9718 - val_loss: 0.1879 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1502 - accuracy: 0.9718 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1477 - accuracy: 0.9789 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1455 - accuracy: 0.9789 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.9789 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9859 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1387 - accuracy: 0.9859 - val_loss: 0.1729 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.9859 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1344 - accuracy: 0.9859 - val_loss: 0.1684 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1323 - accuracy: 0.9859 - val_loss: 0.1664 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1303 - accuracy: 0.9859 - val_loss: 0.1642 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1283 - accuracy: 0.9930 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.9930 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1246 - accuracy: 0.9930 - val_loss: 0.1581 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1227 - accuracy: 0.9930 - val_loss: 0.1561 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.9930 - val_loss: 0.1542 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1192 - accuracy: 0.9930 - val_loss: 0.1523 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1174 - accuracy: 0.9930 - val_loss: 0.1505 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1157 - accuracy: 0.9930 - val_loss: 0.1487 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1141 - accuracy: 0.9930 - val_loss: 0.1469 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9930 - val_loss: 0.1451 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1108 - accuracy: 0.9930 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1093 - accuracy: 0.9930 - val_loss: 0.1415 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.9930 - val_loss: 0.1398 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1062 - accuracy: 0.9930 - val_loss: 0.1382 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9930 - val_loss: 0.1366 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1033 - accuracy: 0.9930 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-68c475f1e3ee>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m history = model.fit(X_train, Y_train,\n\u001b[0m\u001b[1;32m     59\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.src.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.datasets import load_wine\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import genfromtxt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from keras.utils import plot_model\n",
        "\n",
        "def create_custom_model(input_dim, output_dim, nodes, layers=1, name='model'):\n",
        "    # Create model\n",
        "    model = Sequential(name=name)\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(nodes, activation='tanh'))\n",
        "    model.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "wine = load_wine()\n",
        "features = wine['data']\n",
        "target = wine['target']\n",
        "names = wine['target_names']\n",
        "feature_names = wine['feature_names']\n",
        "enc = OneHotEncoder()\n",
        "target = enc.fit_transform(target[:, np.newaxis]).toarray()\n",
        "\n",
        "# Scale data to have mean 0 and variance 1\n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    features_scaled, target, test_size=0.2, random_state=2)\n",
        "\n",
        "n_features = features.shape[1]\n",
        "n_classes = target.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "n_layers = 1  # must be greater than 0\n",
        "n_hidden_neurons = 8\n",
        "model = create_custom_model(n_features, n_classes, n_hidden_neurons, n_layers)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                              batch_size=32,\n",
        "                              epochs=200,\n",
        "                              verbose=1,\n",
        "                              validation_data=(X_test, Y_test))\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.datasets import load_wine\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from keras.utils import plot_model\n",
        "\n",
        "def create_custom_model(input_dim, output_dim, nodes, layers=1, name='model'):\n",
        "    # Create model\n",
        "    model = Sequential(name=name)\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(nodes, activation='tanh'))\n",
        "    model.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "wine = load_wine()\n",
        "features = wine['data']\n",
        "target = wine['target']\n",
        "names = wine['target_names']\n",
        "feature_names = wine['feature_names']\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "target = enc.fit_transform(target[:, np.newaxis]).toarray()\n",
        "\n",
        "# Scale data to have mean 0 and variance 1\n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "feataures_scaled = scaler.fit_transform(features)\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    features_scaled, target, test_size=0.2, random_state=2)\n",
        "\n",
        "n_features = features.shape[1]\n",
        "n_classes = target.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "n_layers = 3 # must be greater than 0\n",
        "n_hidden_neurons = 8\n",
        "model = create_custom_model(n_features, n_classes, n_hidden_neurons, n_layers)\n",
        "\n",
        "model.summary()\n",
        "# Plot model graph\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='mode2l.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='mode2l.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "WFadJflshnt9",
        "outputId": "d3ada395-656e-4cb1-c0b7-3788bb3282b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 8)                 112       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139 (556.00 Byte)\n",
            "Trainable params: 139 (556.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 150,
              "height": 147
            }
          },
          "execution_count": 9
        }
      ]
    }
  ]
}